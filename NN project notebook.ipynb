{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "full_train_set = pd.read_csv('../input/train.csv')\n",
    "submission_test_set = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = full_train_set.target\n",
    "X = full_train_set.drop('target', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance - class imbalance 1:9\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, submission_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_train_set.iloc[0:100, 0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(full_train_set.iloc[:, 0:7].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_set.var_0.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test_set.var_0.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_values = []\n",
    "for col in full_train_set:\n",
    "    train_unique_values.append(full_train_set[col].unique().shape[0])\n",
    "    \n",
    "train_unique_values = train_unique_values[2:]\n",
    "    \n",
    "test_unique_values = []\n",
    "for col in submission_test_set:\n",
    "    test_unique_values.append(submission_test_set[col].unique().shape[0])\n",
    "    \n",
    "test_unique_values = test_unique_values[1:]\n",
    "\n",
    "len(train_unique_values), len(test_unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_unique_values)\n",
    "plt.plot(test_unique_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set has two times less unique values for every feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding of these synthetic and real samples with help from:\n",
    "# https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split\n",
    "df_test = pd.DataFrame.copy(submission_test_set)\n",
    "df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the synthetic rows\n",
    "#submission_test_set.drop(synthetic_samples_indexes, inplace=True)\n",
    "submission_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stratifiedshufflesplit to get equal class imbalance in each set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create val set\n",
    "for train_index, val_index in sss.split(X_train, y_train):\n",
    "    X_train, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train, y_val = y_train.iloc[train_index], y_train.iloc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move ID_code to index\n",
    "X_train.set_index('ID_code', inplace=True)\n",
    "X_val.set_index('ID_code', inplace=True)\n",
    "X_test.set_index('ID_code', inplace=True)\n",
    "submission_test_set.set_index('ID_code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "#from boostaroota import BoostARoota\n",
    "#r = BoostARoota(metric='aucpr')\n",
    "#br = BoostARoota(metric='logloss')\n",
    "#Fit the model for the subset of variables\n",
    "#br.fit(X_train, y_train)\n",
    "\n",
    "#Can look at the important variables - will return a pandas series\n",
    "#br.keep_vars_\n",
    "\n",
    "#Then modify dataframe to only include the important variables\n",
    "#br.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boruta\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from boruta import BorutaPy\n",
    "#rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced', max_depth=6)\n",
    "#boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
    "#boruta_selector.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CatBoost model as base reference\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "model = CatBoostClassifier(\n",
    "    eval_metric='WKappa',\n",
    "    random_seed=42,\n",
    "    logging_level='Silent',\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    #cat_features=categorical_features_indices,\n",
    "    eval_set=(X_val, y_val),\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and find AUC on test set\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "y_predict = model.predict(X_test)\n",
    "roc_test_score = roc_auc_score(y_test, y_predict)\n",
    "print(roc_test_score)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n",
    "space = {\n",
    "    'iterations': hp.quniform('iterations', 500, 4000, 50),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    'l2_leaf_reg': hp.quniform('l2_leaf_reg', 1, 50, 1),\n",
    "    'random_strength' : hp.quniform('random_strength', 1, 50, 1),\n",
    "    'depth' : hp.quniform('depth', 1, 11, 1),\n",
    "    'early_stopping_rounds' : hp.quniform('early_stopping_rounds', 0, 100, 5),\n",
    "    'od_type' : True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt.pyll.stochastic\n",
    "print(hyperopt.pyll.stochastic.sample(space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "counter = 1\n",
    "def objective(params):\n",
    "    global counter\n",
    "    start_time = time.time()\n",
    "    print(\"Starting %s trial\" % counter)\n",
    "    clf = CatBoostClassifier(**params)\n",
    "    clf.use_best_model = True\n",
    "    clf.random_seed = 42\n",
    "    \n",
    "    X_trial = pd.DataFrame.copy(X)\n",
    "    y_trial = pd.DataFrame.copy(y)\n",
    "    \n",
    "    X_trial.set_index('ID_code', inplace=True)\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "\n",
    "    for train_index, val_index in sss.split(X_trial, y_trial):\n",
    "        X_train, X_val = X_trial.iloc[train_index], X_trial.iloc[val_index]\n",
    "        y_train, y_val = y_trial.iloc[train_index], y_trial.iloc[val_index]\n",
    "        \n",
    "    \n",
    "    print(\"Started training...\")\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_set=(X_val, y_val))\n",
    "\n",
    "    y_predict = model.predict(X_val)\n",
    "    roc_test_score = roc_auc_score(y_val, y_predict)\n",
    "    counter += 1\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = (end_time - start_time) / 60\n",
    "    \n",
    "    print(params)\n",
    "    print(\"AUROC is %s, took %f minutes\" % (roc_test_score, duration))\n",
    "    return {'loss': 1 - roc_test_score, 'auroc': roc_test_score, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission_predict = model.predict(submission_test_set)\n",
    "y_submission_predict = y_submission_predict.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_submission_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_variable = pd.DataFrame({'ID_code' : submission_test_set.index.values, 'target': y_submission_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_variable.to_csv('csv_to_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"csv_to_submit.csv\"> Download File </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
