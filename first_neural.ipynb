{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.regularizers import l1_l2, l1\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "full_train_set = pd.read_csv('../input/train.csv')\n",
    "submission_test_set = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = full_train_set.target\n",
    "X = full_train_set.drop('target', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_values = []\n",
    "for col in full_train_set:\n",
    "    train_unique_values.append(full_train_set[col].unique().shape[0])\n",
    "    \n",
    "train_unique_values = train_unique_values[2:]\n",
    "    \n",
    "test_unique_values = []\n",
    "for col in submission_test_set:\n",
    "    test_unique_values.append(submission_test_set[col].unique().shape[0])\n",
    "    \n",
    "test_unique_values = test_unique_values[1:]\n",
    "\n",
    "len(train_unique_values), len(test_unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split\n",
    "df_test = pd.DataFrame.copy(submission_test_set)\n",
    "df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_rows = submission_test_set.iloc[synthetic_samples_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the synthetic rows\n",
    "#submission_test_set.drop(synthetic_samples_indexes, inplace=True) try this afterwards\n",
    "submission_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move ID_code to index\n",
    "X.set_index('ID_code', inplace=True)\n",
    "submission_test_set.set_index('ID_code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture base idea from \n",
    "# https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/applications/porto_seguro_keras_under_sampling.html\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=200, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_imbalanced_model(X_train, y_train, X_test, y_test):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=32, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_model = fit_predict_imbalanced_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try balanced minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.keras import BalancedBatchGenerator\n",
    "\n",
    "def fit_predict_balanced_model(X_train, y_train, X_test, y_test):\n",
    "    model = make_model()\n",
    "    training_generator = BalancedBatchGenerator(X_train, y_train,\n",
    "                                                batch_size=32,\n",
    "                                                random_state=42)\n",
    "    model.fit_generator(generator=training_generator, epochs=100, verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_trained_model = fit_predict_balanced_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = balanced_trained_model.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "weights = compute_class_weight('balanced', [0, 1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_imbalanced_model(X_train, y_train, X_test, y_test):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=2, batch_size=1000, validation_split=0.2, class_weight=weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_model = fit_predict_imbalanced_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=1, random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_undersampled_model(X_train, y_train):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=32, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_model = fit_predict_undersampled_model(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersample 1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_undersampled_model(X_train, y_train):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=1000, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_model = fit_predict_undersampled_model(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_oversampled_model(X_train, y_train):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=1000, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_model = fit_predict_oversampled_model(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aurocs = []\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "counter = 1\n",
    "for train_index, val_index in sss.split(X_train, y_train):\n",
    "    print(\"Starting fold %i\" % counter)\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_train_cv, y_train_cv)\n",
    "    trained_model = fit_predict_oversampled_model(X_res, y_res)\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_pred)\n",
    "    print(auroc)\n",
    "    aurocs.append(auroc)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_oversampled_model(X_train, y_train):\n",
    "    model = make_model()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=500)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aurocs = []\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "counter = 1\n",
    "for train_index, val_index in sss.split(X_train, y_train):\n",
    "    print(\"Starting fold %i\" % counter)\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    sm = SMOTEENN(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_train_cv, y_train_cv)\n",
    "    np.bincount(y_res)\n",
    "    trained_model = fit_predict_oversampled_model(X_res, y_res)\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_pred)\n",
    "    print(auroc)\n",
    "    aurocs.append(auroc)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_train_set['target']\n",
    "y.head()\n",
    "X_filtered = full_train_set[y > 0].copy()\n",
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment method from here: https://www.kaggle.com/roydatascience/eda-pca-simple-lgbm-on-kfold-technique\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        print(\"First loop\")\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        print(\"Second loop\")\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "    print(\"Final part\")\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof = full_train_set[['ID_code', 'target']]\n",
    "oof['predict'] = 0\n",
    "predictions = submission_test_set[['ID_code']]\n",
    "val_aucs = []\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in full_train_set.columns if col not in ['target', 'ID_code']]\n",
    "X_test = submission_test_set[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = fit_predict_oversampled_model(X_t, y_t) # Maybe remove validation split inside here\n",
    "y_pred = trained_model.predict(X_val_cv)\n",
    "\n",
    "val_score = roc_auc_score(y_val_cv, y_pred)\n",
    "aurocs.append(val_score)\n",
    "print(val_score)\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aurocs = []\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "counter = 1\n",
    "for train_index, val_index in sss.split(full_train_set, full_train_set['target']):\n",
    "    print(\"Starting fold %i\" % counter)\n",
    "    X_train_cv, X_val_cv = full_train_set.iloc[train_index][features], full_train_set.iloc[val_index][features]\n",
    "    y_train_cv, y_val_cv = full_train_set.iloc[train_index]['target'], full_train_set.iloc[val_index]['target']\n",
    "    \n",
    "    print(len(y_train_cv.values))\n",
    "    X_t, y_t = augment(X_train_cv.values, y_train_cv.values)\n",
    "    print(len(X_t))\n",
    "    print(y_t)\n",
    "    X_t = pd.DataFrame(X_t)\n",
    "    X_t = X_t.add_prefix('var_')\n",
    "    \n",
    "    y_int = y_t.astype(int)\n",
    "    np.bincount(y_int)\n",
    "    \n",
    "    trained_model = fit_predict_oversampled_model(X_t, y_t) # Maybe remove validation split inside here\n",
    "    y_pred = trained_model.predict(X_val_cv)\n",
    "\n",
    "    val_score = roc_auc_score(y_val_cv, y_pred)\n",
    "    aurocs.append(val_score)\n",
    "    print(val_score)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = roc_auc_score(y_val_cv, y_pred)\n",
    "aurocs.append(val_score)\n",
    "print(val_score)\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying feature magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature magic from here: https://www.kaggle.com/dott1718/922-in-3-minutes\n",
    "features = [x for x in full_train_set.columns if x.startswith(\"var\")]\n",
    "\n",
    "hist_df = pd.DataFrame()\n",
    "for var in features:\n",
    "    var_stats = full_train_set[var].append(submission_test_set[var]).value_counts()\n",
    "    hist_df[var] = pd.Series(submission_test_set[var]).map(var_stats)\n",
    "    hist_df[var] = hist_df[var] > 1\n",
    "\n",
    "ind = hist_df.sum(axis=1) != 200\n",
    "var_stats = {var:full_train_set[var].append(submission_test_set[ind][var]).value_counts() for var in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = features.copy()\n",
    "\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    column_values = var_stats[feature][full_train_set[feature]].values\n",
    "    full_train_set['count_' + feature] = column_values \n",
    "    new_features.append('count_' + feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_new():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=400, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(full_train_set[new_features], full_train_set['target']):\n",
    "    X_train, X_test = full_train_set[new_features].iloc[train_index], full_train_set[new_features].iloc[test_index]\n",
    "    y_train, y_test = full_train_set['target'].iloc[train_index], full_train_set['target'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_new_features_model(X_train, y_train):\n",
    "    model = make_model_new()\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=2, batch_size=128)\n",
    "    return model\n",
    "\n",
    "trained_model = fit_new_features_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = sc.fit_transform(submission_test_set)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission_predict = classifier.predict(X_final_test)\n",
    "print(y_submission_predict)\n",
    "#y_submission_predict = y_submission_predict.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_final_predict = list()\n",
    "for value in y_submission_predict:\n",
    "    y_final_predict.append(value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_variable = pd.DataFrame({'ID_code' : submission_test_set.index.values, 'target': y_final_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_variable.to_csv('csv_to_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"csv_to_submit.csv\"> Download File </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
